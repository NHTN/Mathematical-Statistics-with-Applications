{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting là gì?\n",
    "#### Ý tưởng:\n",
    "Thay vì xây dựng một mô hình dự đoán (chẳng hạn descision tree) có độ chính xác tương đối, ta đi xây dựng nhiều mô hình dự đoán có độ chính xác kém hơn (weak learner) khi đi riêng lẻ nhưng lại cho độ chính xác cao khi kết hợp lại.\n",
    "\n",
    "Ta có thể hình dung mỗi weak learner gồm học sinh yếu, khá, giỏi và thầy giáo. Trong đó, trọng số uy tín về kiến thức của thầy giáo sẽ là cao nhất và học sinh yếu sẽ là thấp nhất. Khi bạn đặt câu hỏi nào đó và cần những người này đưa ra kết luận, nếu nhiều người cùng có chung kết luận hoặc uy tín của những người đưa ra kết luận cao hơn tập thể thì ta có thể tin kết luận này là đúng.\n",
    "\n",
    "Ví dụ trong thuật toán AdaBoost, mỗi lần huấn luyện weak learner, mô hình sẽ tính lại trọng số cho các điểm dữ liệu đã bị phân lớp sai, để những lượt huấn luyện tiếp theo những điểm dữ liệu này sẽ có cơ hội nhiều hơn được phân lớp đúng. Dưới đây là mô hình dự đoán tổng quát:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(\\mathbf{x}) = sign(\\alpha_1 h_1(\\mathbf{x}) + \\alpha_2 h_2(\\mathbf{x}) + ... + \\alpha_k h_k(\\mathbf{x}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent là gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mục tiêu</b>: tìm vector các tham số sao cho tối ưu hoá hàm mục tiêu cụ thể nào đó:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{P^*} = argmin_\\mathbf{P} \\Phi(\\mathbf{P})$<br>\n",
    "Phương pháp Gradient descent:<br>\n",
    "\n",
    "Gradient: $\\mathbf{g}_m = \\{g_{jm}\\} = \\{\\lbrack \\frac{\\partial \\Phi(\\mathbf{P})}{\\partial P_j} \\rbrack_{\\mathbf{P}=\\mathbf{P}_{m-1}}\\}$<br>\n",
    "Parameters: $\\mathbf{p}_m = -\\rho_m \\mathbf{g}_m$<br>\n",
    "Learning rate: $\\rho_m = argmin_\\rho \\Phi(\\mathbf{P}_{m-1} - \\rho \\mathbf{g}_m)$<br>\n",
    "Target parameters: $\\mathbf{P^*} = \\Sigma_{m=0}^M \\mathbf{p}_m$<br>\n",
    "Như vậy, kết quả của gradient descent là weighted combination của các gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết hợp hai hướng tiếp cận"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy, mục tiêu của chúng ta là đi xây dựng additive model:<br>\n",
    "\n",
    "$F(\\mathbf{x};\\{\\beta_m, \\mathbf{a}_m\\}_1^M = \\Sigma_{m=1}^M \\beta_m h(x; \\mathbf{a}_m))$<br>\n",
    "\n",
    "Nhưng sẽ rất khó nếu ta huấn luyện trực tiếp để tìm tập parameters trong không gian tham số:<br>\n",
    "\n",
    "$\\{\\beta_m, \\mathbf{a}_m\\}_1^M = argmin_{\\{\\beta_m', \\mathbf{a}_m'\\}}\\Sigma_{i=1}^N L (y_i, \\Sigma_{m=1}^M \\beta_m' h(\\mathbf{x}_i, \\mathbf{a}_m'))$<br>\n",
    "\n",
    "Vì vậy, ta sẽ dùng greedy-stagewise trong không gian hàm số để giải:\n",
    "\n",
    "$(\\beta_m, \\mathbf{a}_m) = argmin_{\\beta, a} \\Sigma_{i=1}^N L(y_i, F_{m-1}(\\mathbf{x}_i) + \\beta h(\\mathbf{x}_i;a))$<br>\n",
    "\n",
    "khi đó,<br>\n",
    "\n",
    "$F_m(\\mathbf{x}) = F_{m-1}(\\mathbf{x}) + \\beta_m h(\\mathbf{x};\\mathbf{a}_m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thuật toán Gradient boosting tổng quát"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thuật toán này nhằm xấp xỉ gradient thông qua một hàm tham số hoá $h(\\mathbf{x}; \\mathbf{a}_m)$. Tại mỗi vòng lặp: ta tính gradient $\\tilde{y}_m$. Ta xem$\\{-\\tilde{y}_i, \\mathbf{x}_i\\}_1^N$ là tập training để huấn luyện hàm $h(\\mathbf{x}; \\mathbf{a}_m)$. Từ đó, ta có thể dự đoán $-\\tilde{y}_m từ \\mathbf{x}$.<br>\n",
    "\n",
    "Gradient_Boost()<br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;\n",
    " $ F_0(\\mathbf{x}) = argmin_\\rho \\Sigma_{i=1}^N L(y_i, \\rho)$<br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp; \n",
    " For m = 1 to M do:<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  $\\#$ gradient step<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  $\\tilde{y} = -\\lbrack \\frac{\\partial L(y_i, F(\\mathbf{x_i}))}{\\partial F(\\mathbf{x_i})} \\rbrack_{F(\\mathbf{x}) = F_{m-1}(\\mathbf{x})}, i = 1, N$<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  $a_m = argmin_{a, \\beta} \\Sigma_{i=1}^N \\lbrack \\tilde{y} - \\beta h(x_i; a) \\rbrack$<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  $\\#$ boosting step<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  $\\rho_m = argmin_\\rho \\Sigma_{i=1}^N L(y_i, F_{m-1}(x_i) + \\rho h(x_i; \\mathbf{a_m})$<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  $F_m(\\mathbf{x}) = F_{m-1}(\\mathbf{x}) + \\rho_m h(x; \\mathbf{a_m})$<br>\n",
    " &nbsp;&nbsp;&nbsp;&nbsp;endFor<br>\n",
    "endAlgorithm<br>\n",
    "\n",
    "Như vậy, $\\tilde{y}_i$ vừa là gradient của function space vừa là label của parameter space. $\\beta$ là leanring rate để tìm tham số $\\mathbf{a}_m$ và $\\rho_m$ là learning rate để boosting additive model $F_m(\\mathbf{x})$.\n",
    "\n",
    "Từ thuật toán cơ sở này, ta có thể mở rộng cho các mô hình khác thông qua loss function được định nghĩa trước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost <br>\n",
    "<div >\n",
    "Đặt:\n",
    "\n",
    "$n$: số lượng mẫu huấn luyện.<br>\n",
    "$m$: số lượng features.<br>\n",
    "$\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\} $ là tập dữ liệu với $|\\mathcal{D}| = n,\\mathbf{x}_i \\in \\mathbb{R}^m, y_i \\in \\mathbb{R}$.<br>\n",
    "$q$: cấu trúc của một cây, ánh xạ mẫu dữ liệu vào nút lá tương ứng.<br>\n",
    "$T$: số lượng nút lá trên cây.<br>\n",
    "$f_k$: cấu trúc các cây $k$ độc lập của mô hình.<br>\n",
    "$L$ : Hàm mất mát (loss function)<br>\n",
    "$w_i$: trọng số của nút lá thứ $i$.<br>\n",
    "$\\hat{y}_i^{(t)}$: giá trị dự đoán của instance thứ $i$ tại vòng lặp thứ $t$.<br>\n",
    "$f_t^2(\\mathbf{x}_i)$: đạo hàm bậc 2 của hàm $f$.<br>\n",
    "$I_j = \\{i|q(\\mathbf{x}_i) = j\\}$: tập các giá trị tại nút lá $j$<br>\n",
    "$I_L$: tập giá trị nút lá bên trái.<br>\n",
    "$I_R$: tập giá trị nút lá bên phải.<br>\n",
    "$I = I_L \\cup I_R$.<br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ý tưởng đằng sau mô hình:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giả sử chúng ta có cây $K$, mô hình là:<br>\n",
    "    $\\Sigma_{k=1}^K f_k$<br>\n",
    "Trong đó $f_k$ là một dự đoán từ một cây quyết định.<br>\n",
    "Cho nên có thể thấy mô hình thực chất là một tập các cây quyết định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "    <b>Mô hình học:</b><br>\n",
    "\n",
    "<p style=\"text-align:center\">$\\hat{y}_i = \\phi(\\mathbf{x}_i) = \\Sigma_{k=1}^K f_k(\\mathbf{x}_i), f_k \\in \\mathcal{F}$.<br></p>\n",
    "Trong đó:<br> \n",
    "    <ul>\n",
    "        <li>$\\mathbf{x}_i$ là vector đặc trưng cho điểm dữ liệu thứ $i$ </li>\n",
    "    <li>$\\mathcal{F} = \\{f(\\mathbf{x}) = w_{q(\\mathbf{x})}\\} (q : \\mathbb{R}^m) \\rightarrow T, w \\in \\mathbb{R}^T$.<br></li>\n",
    "    </ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     <b>Hàm học:</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để train mô hình, chúng ta cần tối ưu một hàm mất mát (loss function).\n",
    "Thông thường chúng ta sẽ sử dụng:\n",
    "<ul>\n",
    "    <li>\n",
    "        Rooted Mean Squared Error cho hồi quy(regression)<br>\n",
    "    $L = \\frac{1}{N} \\Sigma_{i=1}^N (y_i - \\hat{y}_i)^2   $\n",
    "    </li>\n",
    "    <li>LogLoss cho binary classification<br>\n",
    "    $L = - \\frac{1}{N} \\Sigma_{i=1}^N (y_i\\log(p_i) + (1-y_i)\\log(1- p_i)   $\n",
    "    </li>\n",
    "    <li>mlogloss cho multi-classification<br>\n",
    "    $L = - \\frac{1}{N} \\Sigma_{i=1}^N \\Sigma_{j=1}^M (y_{i,j}\\log(p_{i,j})    $\n",
    "    </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chính quy hóa (Regularization) là một phần quan trọng khác của mô hình.<br>\n",
    "Một công thức chính quy hoá tốt kiểm soát mức độ phức tạp của mô hình, ngăn cản việc bị overfitting<br>\n",
    "<i>Định nghĩa hàm mất mát trong mô hình:</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = \"text-align:center\">$\\Omega = \\gamma T + \\frac{1}{2} \\lambda \\Sigma_{j=1}^T w_j^2$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết hợp hàm mất mát với hàm chính quy hóa ta được đối tượng của mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = \"text-align:center\">$Obj = \\mathcal{L}(\\phi) = L + \\Omega$</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "Vậy ta có hàm học tổng quát cho mô hình như sau:<br>\n",
    "\n",
    "<p style = \"text-align:center\">$\\mathcal{L}(\\phi) = \\Sigma_i l(\\hat{y}_i, y_i) + \\Sigma_k \\Omega(f_k)$ </p>\n",
    "  Trong đó,<br>\n",
    "    <ul>\n",
    "        <li>$\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda |w|^2$</li>\n",
    "        <li>$ \\Sigma_i l(\\hat{y}_i, y_i)$ là hàm mất mát tùy thuộc từng mô hình</li>\n",
    "    </ul>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong XGBoost, chúng ta sử dụng gradient descent để tối ưu Objective(mục tiêu)<br>\n",
    "Cho trước một objective $Obj(y,\\hat y)$ để tối ưu, gradient descent là một kỹ thuật lặp đi lặp lại để tính:<br>\n",
    "<p style = \"text-align:center\"> $\\partial_{\\hat{y}} Obj(y,\\hat{y})$ </p>\n",
    "tại mỗi lần lặp. Sau đó chúng ta cải thiện $\\hat{y}$ dọc theo hướng của gradient để giảm thiểu objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiến trình học:\n",
    "Đối với thuật toán lặp, chúng ta có thể xác định lại hàm mục tiêu là\n",
    "<p >$Obj^{(t)} = \\Sigma_{i=1}^N L(y_i, \\hat{y}_i^{(t)}) + \\Sigma_{i=1}^t \\Omega(f_i)$ <br>\n",
    "$= \\Sigma_{i=1}^N L(y_i, \\hat{y}_i^{(t-1)} + f_t(\\mathbf{x}_i)) + \\Sigma_{i=1}^t \\Omega(f_i)$</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Để tối ưu hóa nó bằng gradient descent, chúng ta cần tính toán gradient. Hiệu suất cũng có thể được cải thiện bằng cách xem xét cả gradient bậc 1 và bậc 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\partial_{\\hat{y}^{(t)}} Obj^{(t)}$<br>\n",
    "$\\partial_{\\hat{y}^{(t)}}^{2} Obj^{(t)}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì chúng ta không có đạo hàm cho mọi hàm mục tiêu, chúng ta sẽ tính toán xấp xỉ taylor bậc hai của nó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Obj^{(t)} \\sim \\Sigma_{i=1}^N \\lbrack L(y_i, \\hat{y}^{(t-1)}) + g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i) \\rbrack + \\Sigma_{i=1}^t\\Omega(f_i)$ <br>\n",
    "\n",
    "với,<br>\n",
    "<ul>\n",
    "    <li>$g_i = \\partial_{\\hat{y}^{(t-1)}} l(y_i, \\hat{y}^{(t-1)})$</li> \n",
    "    <li> $h_i = \\partial_{\\hat{y}^{(t-1)}}^2 l(y_i, \\hat{y}^{(t-1)}).$</li>\n",
    "    </ul><br>\n",
    "Loại hằng số, ta có:<br>\n",
    "$Obj^{(t)} = \\Sigma_{i=1}^n \\lbrack g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i) \\rbrack + \\Omega(f_t)$<br>\n",
    "$Obj^{(t)} = \\Sigma_{i=1}^n \\lbrack g_i f_t(x_i) + \\frac{1}{2} h_i f_t^2(x_i) \\rbrack + \\gamma T + \\frac{1}{2} \\lambda \\Sigma_{j=1}^T w_j^2 $ <br>\n",
    "$Obj^{(t)} = \\Sigma_{j=1}^T \\lbrack (\\Sigma_{i \\in I_j} g_i)w_j + \\frac{1}{2}(\\Sigma_{i \\in I_j} h_i + \\lambda)w_j^2 \\rbrack + \\gamma T.$<br>\n",
    "\n",
    "Trọng số tối ưu tại mỗi nút lá: $w_j^* = -\\frac{\\Sigma_{i\\in I_j} g_i}{\\Sigma_{i\\in I_j} h_i + \\lambda}$<br>\n",
    "        trong đó: $g$ và $h$ lần lượt là hàm mất mát bậc 1 và bậc 2<br>\n",
    "        $\\lambda $ là tham số chính quy hóa\n",
    "Hàm lỗi tính trên toàn bộ cây: $Obj^{(t)} = -\\frac{1}{2} \\Sigma_{j=1}^T \\frac{(\\Sigma_{i\\in I_j} g_i)^2}{\\Sigma_{i \\in I_j} h_i + \\lambda} + \\gamma T$<br>\n",
    "\n",
    "Điều kiện rẽ nhánh:<br>\n",
    "\n",
    "$Obj_{split}= gain = \\frac{1}{2} \\lbrack \\frac{\\Sigma_{i\\in I_L} g_i)^2}{\\Sigma_{i \\in I_L} h_i + \\lambda} + \\frac{\\Sigma_{i\\in I_R} g_i)^2}{\\Sigma_{i \\in I_R} h_i + \\lambda} - \\frac{\\Sigma_{i\\in I} g_i)^2}{\\Sigma_{i \\in I} h_i + \\lambda} \\rbrack - \\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class xgboost.XGBClassifier(objective='binary:logistic', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mặc định mô hình này sẽ sử dụng binary logistic cho bài toán phân loại(classification).\n",
    "Nhưng vì số lượng nhãn trong dữ liệu > 2 nên sẽ dùng:<br>\n",
    "objective='multi:softprob'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Một số tham số đáng chú ý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "    <b>booster</b>\n",
    "    <ul>\n",
    "        <li> <b>gbtree</b> tree-based model</li>\n",
    "        <li><b>gblinear</b> linear function</li>\n",
    "    </ul><br>\n",
    "</li>\n",
    "    <li>\n",
    "    <b>objective</b>\n",
    "    <ul>\n",
    "        <li> binary:logistic</li>\n",
    "        <li>multi:softprob</li>\n",
    "        <li>...</li>\n",
    "    </ul><br>\n",
    "</li>\n",
    "    </ul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>XGBoost</b> và <b>Gradient boosting </b> đều dựa trên cùng ý tưởng đó là boosting thông qua gradient descent trong không gian hàm số. Tuy nhiên, điều làm nên hiệu suất ấn tượng và khả năng tính toán của XGBoost nằm ở ba yếu tố:\n",
    "<ul>\n",
    "<li>Engineering để tránh overfitting như: sub-sampling row, column, column per split levels, áp dụng regularized L1 và L2.</li>\n",
    "<li>Khả năng tận dụng tài nguyên hệ thống: tính toán song song trên CPU/GPU, tính toán phân tán trên nhiều server, tính toán khi tài nguyên bị giới hạn, cache optimization để tăng tốc training.</li>\n",
    "<li>Và cuối cùng là khả năng xử lý missing data value, tiếp tục training bằng mô hình đã được build trước đó để tiết kiệm thời gian.</li>\n",
    "    </ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
